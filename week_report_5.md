# 第五周周报

## 学习进度
- 学习了几种以前接触不深的模型的原理，以及优缺点，包括：
    - 决策树模型
    - 集成方法：bagging、boosting
    - 基于bagging的随机森林
    - 基于boosting的Adaboost、GBDT、XGBoost和LightGBM
- 学习了几种数据集划分方法用于评估模型，包括：
    - k折交叉验证
    - 留出法
    - 自助法
- 研究了建模时各参数对模型的影响，以便后续的调参工作

## 比赛报告
这次给出了建模的代码，但是是保存在另一个markdown文件中，我在报告中给出了相应的链接，最后我会在此次项目结束后将notebook的文件上传至github
https://github.com/AmarKingso/DataMiningTraining/blob/master/FinancialRiskControl/FinancialRisk.md

## 学习心得
可以说我前期做的工作都是在为建模打基础，例如转化数据类型用以入模。但最开始并不是很了解lightGBM这个模型，只是拿来跑结果，后来想要提升成绩，就想办法在数据预处理上下功夫。但是由于对模型的不熟悉，导致自己做了很多无用功，例如想着如何进行特征选择以及归一化，后来深入了解了才发现对于lightGBM来说这些处理都不是必要的。后来对异常值的处理让分数也有提升，但提升真的很小，反倒是几次对模型的调参，让成绩有了较大的提升。虽然吧期间做了挺多无用功，但是知识也确实都学到了，就怕之后又会忘了，所以还是要多实践多操作才能让自己记得更牢固。最个人觉得现阶段的分数提高，还是要靠着调参来完成，希望之后学习的调参方法能给我的成绩带来显著的提升吧